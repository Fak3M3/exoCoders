# -*- coding: utf-8 -*-
"""Proyecto_Copy1 (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ArBwtjlewN9YAdRrF89s2NUvQty9K67
"""

# -*- coding: utf-8 -*-
"""
Kepler Exoplanet Classification Project - Improved Version without SMOTE
Focus on improving recall and F1 through better model configuration and feature engineering.

Author: Data Science Team
Date: 2025-10-05
"""
import joblib
import json
import os
import warnings
from typing import Dict, Tuple, Optional, Any
import pickle

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Scientific computing
from scipy import stats
from scipy.fft import fft
from scipy.signal import find_peaks

# Scikit-learn imports
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                           f1_score, confusion_matrix, roc_auc_score,
                           precision_recall_curve, roc_curve, average_precision_score)

# LightGBM
import lightgbm as lgb
from collections import Counter

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Set random seed for reproducibility
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)


class Config:
    """Configuration class optimized for recall improvement without SMOTE."""

    # Data files
    TRAIN_FILE = "exoTrain.csv"
    TEST_FILE = "exoTest.csv"

    # Data processing
    OUTLIER_THRESHOLD = 3.0  # More conservative outlier removal
    IMPUTATION_STRATEGY = 'median'

    # Feature engineering
    ROLLING_WINDOWS = [5, 10, 25, 50, 100]
    FFT_PERCENTILE = 85
    HISTOGRAM_BINS = 50

    # Feature selection
    TARGET_FEATURES = 200  # Optimal number of features
    UNIVARIATE_K = 400
    MUTUAL_INFO_K = 400
    IMPORTANCE_N = 400

    # LightGBM optimized for recall without SMOTE
    LGBM_PARAMS = {
        'objective': 'binary',
        'metric': ['binary_logloss', 'auc'],
        'boosting_type': 'gbdt',
        'num_leaves': 127,  # Increased complexity
        'learning_rate': 0.03,  # Lower learning rate for better convergence
        'feature_fraction': 0.85,
        'bagging_fraction': 0.85,
        'bagging_freq': 5,
        'min_child_samples': 2,  # Very small for minority class
        'min_child_weight': 0.001,  # Very small weight requirement
        'min_split_gain': 0.0,  # Allow any split that improves
        'reg_alpha': 0.0,  # No L1 regularization
        'reg_lambda': 0.01,  # Minimal L2 regularization
        'max_depth': 15,  # Deeper trees
        'verbosity': -1,
        #'is_unbalance': True,
        'seed': RANDOM_STATE,
        'scale_pos_weight': 15,  # High weight for positive class
        'min_data_in_leaf': 1,  # Allow single sample leaves
        'cat_smooth': 1.0,
        'cat_l2': 0.0,
        'boost_from_average': False,  # Don't use average for initialization
    }

    # Cross-validation
    CV_FOLDS = 5
    EARLY_STOPPING_ROUNDS = 150
    NUM_BOOST_ROUNDS = 2000  # More rounds for better learning

    # Test split
    TEST_SIZE = 0.2

    # No threshold optimization - use default 0.5
    CLASSIFICATION_THRESHOLD = 0.5


class DataLoader:
    """Class for loading and initial data validation."""

    @staticmethod
    def load_local_dataset(filepath: str) -> pd.DataFrame:
        """Load dataset from local CSV file."""
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"File not found: {filepath}")

        print(f"Loading dataset from: {filepath}")
        df = pd.read_csv(filepath)
        print(f"Dataset loaded successfully. Shape: {df.shape}")

        if 'LABEL' in df.columns:
            print(f"Label distribution:\n{df['LABEL'].value_counts().sort_index()}")

        return df

    @staticmethod
    def load_train_test_datasets() -> Tuple[pd.DataFrame, Optional[pd.DataFrame]]:
        """Load both training and test datasets."""
        print("=== LOADING DATASETS ===")

        # Load training data
        train_df = DataLoader.load_local_dataset(Config.TRAIN_FILE)

        # Try to load test data
        test_df = None
        try:
            test_df = DataLoader.load_local_dataset(Config.TEST_FILE)
            print("Both training and test datasets loaded successfully.")
        except FileNotFoundError:
            print(f"Test file '{Config.TEST_FILE}' not found. Will use train-test split.")

        return train_df, test_df


class DataPreprocessor:
    """Handles data cleaning and preprocessing without aggressive modifications."""

    def __init__(self):
        self.scaler: Optional[RobustScaler] = None
        self.imputer: Optional[SimpleImputer] = None

    def clean_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """Clean and prepare the dataset with conservative preprocessing."""
        print("Starting conservative data cleaning...")

        # Create copy to avoid modifying original
        df_clean = df.copy()

        # Separate features and labels
        if 'LABEL' not in df_clean.columns:
            raise ValueError("Dataset must contain 'LABEL' column")

        X = df_clean.drop('LABEL', axis=1)
        y = df_clean['LABEL']

        # Handle missing values
        missing_count = X.isnull().sum().sum()
        print(f"Missing values found: {missing_count}")

        if missing_count > 0:
            self.imputer = SimpleImputer(strategy=Config.IMPUTATION_STRATEGY)
            X_imputed = pd.DataFrame(
                self.imputer.fit_transform(X),
                columns=X.columns,
                index=X.index
            )
        else:
            X_imputed = X

        # Conservative outlier handling
        X_clean = self._handle_outliers_conservative(X_imputed)

        # Remove only truly constant features
        X_clean = self._remove_constant_features(X_clean)

        print(f"Data cleaning completed. Final shape: {X_clean.shape}")
        return X_clean, y

    def _handle_outliers_conservative(self, X: pd.DataFrame) -> pd.DataFrame:
        """Very conservative outlier handling to preserve minority class patterns."""
        print("Applying conservative outlier handling...")

        Q1 = X.quantile(0.25)
        Q3 = X.quantile(0.75)
        IQR = Q3 - Q1

        # Very conservative bounds
        lower_bound = Q1 - Config.OUTLIER_THRESHOLD * IQR
        upper_bound = Q3 + Config.OUTLIER_THRESHOLD * IQR

        # Use very soft clipping (99.9th percentiles)
        X_clean = X.copy()
        for col in X_clean.columns:
            p01 = X_clean[col].quantile(0.001)
            p999 = X_clean[col].quantile(0.999)

            # Only clip extreme outliers
            X_clean[col] = X_clean[col].clip(lower=p01, upper=p999)

        print("Conservative outlier handling completed")
        return X_clean

    def _remove_constant_features(self, X: pd.DataFrame) -> pd.DataFrame:
        """Remove only truly constant features."""
        print("Removing constant features...")

        # Remove only exactly constant features
        constant_features = X.columns[X.var() == 0].tolist()

        if constant_features:
            print(f"Removing {len(constant_features)} constant features")
            X_clean = X.drop(columns=constant_features)
        else:
            X_clean = X

        return X_clean

    def scale_features(self, X_train: pd.DataFrame,
                      X_test: Optional[pd.DataFrame] = None) -> Tuple[pd.DataFrame, Optional[pd.DataFrame]]:
        """Scale features using RobustScaler."""
        print("Scaling features...")

        self.scaler = RobustScaler()
        X_train_scaled = pd.DataFrame(
            self.scaler.fit_transform(X_train),
            columns=X_train.columns,
            index=X_train.index
        )

        if X_test is not None:
            X_test_scaled = pd.DataFrame(
                self.scaler.transform(X_test),
                columns=X_test.columns,
                index=X_test.index
            )
            return X_train_scaled, X_test_scaled

        return X_train_scaled, None


class FeatureEngineer:
    """Enhanced feature engineering optimized for minority class detection."""

    def create_statistical_features(self, X: pd.DataFrame) -> pd.DataFrame:
        """Create comprehensive statistical features."""
        print("Creating statistical features...")

        features = pd.DataFrame(index=X.index)

        # Basic statistics
        features['mean_flux'] = X.mean(axis=1)
        features['median_flux'] = X.median(axis=1)
        features['std_flux'] = X.std(axis=1)
        features['var_flux'] = X.var(axis=1)
        features['min_flux'] = X.min(axis=1)
        features['max_flux'] = X.max(axis=1)
        features['range_flux'] = features['max_flux'] - features['min_flux']

        # Quantiles
        for q in [0.05, 0.25, 0.75, 0.95]:
            features[f'q{int(q*100)}_flux'] = X.quantile(q, axis=1)

        # Advanced statistics
        features['skewness'] = X.skew(axis=1)
        features['kurtosis'] = X.kurtosis(axis=1)
        features['mad'] = X.apply(lambda row: np.median(np.abs(row - row.median())), axis=1)
        features['cv_flux'] = features['std_flux'] / (features['mean_flux'].abs() + 1e-8)

        # Zero crossings and patterns
        features['zero_crossings'] = X.apply(
            lambda row: np.sum(np.diff(np.sign(row - row.mean())) != 0), axis=1
        )

        return features

    def create_rolling_features_fixed(self, X: pd.DataFrame) -> pd.DataFrame:
        """Create rolling window features - FIXED VERSION without axis parameter."""
        print("Creating rolling window features (fixed)...")

        features = pd.DataFrame(index=X.index)

        for window in Config.ROLLING_WINDOWS:
            if window < X.shape[1]:
                # Calculate rolling statistics manually to avoid axis parameter issue
                rolling_means = []
                rolling_stds = []
                rolling_mins = []
                rolling_maxs = []

                for i in range(len(X)):
                    row_values = X.iloc[i].values

                    # Calculate rolling windows for this row
                    if len(row_values) >= window:
                        # Use multiple windows across the time series
                        window_stats = []
                        step = max(1, (len(row_values) - window) // 5)  # 5 windows per row

                        for start in range(0, len(row_values) - window + 1, step):
                            window_data = row_values[start:start + window]
                            window_stats.append({
                                'mean': np.mean(window_data),
                                'std': np.std(window_data),
                                'min': np.min(window_data),
                                'max': np.max(window_data)
                            })

                        if window_stats:
                            rolling_means.append(np.mean([w['mean'] for w in window_stats]))
                            rolling_stds.append(np.mean([w['std'] for w in window_stats]))
                            rolling_mins.append(np.min([w['min'] for w in window_stats]))
                            rolling_maxs.append(np.max([w['max'] for w in window_stats]))
                        else:
                            rolling_means.append(np.mean(row_values))
                            rolling_stds.append(np.std(row_values))
                            rolling_mins.append(np.min(row_values))
                            rolling_maxs.append(np.max(row_values))
                    else:
                        rolling_means.append(np.mean(row_values))
                        rolling_stds.append(np.std(row_values))
                        rolling_mins.append(np.min(row_values))
                        rolling_maxs.append(np.max(row_values))

                # Add to features
                features[f'rolling_mean_{window}'] = rolling_means
                features[f'rolling_std_{window}'] = rolling_stds
                features[f'rolling_min_{window}'] = rolling_mins
                features[f'rolling_max_{window}'] = rolling_maxs
                features[f'rolling_range_{window}'] = np.array(rolling_maxs) - np.array(rolling_mins)

        return features

    def create_frequency_features(self, X: pd.DataFrame) -> pd.DataFrame:
        """Create frequency domain features for transit detection."""
        print("Creating frequency domain features...")

        features = pd.DataFrame(index=X.index)

        for i, row in X.iterrows():
            values = row.values

            # FFT analysis
            fft_values = np.abs(fft(values))
            fft_power = fft_values ** 2

            # Spectral features
            total_power = np.sum(fft_power)
            if total_power > 0:
                freq_range = np.arange(len(fft_values))
                features.loc[i, 'spectral_centroid'] = np.sum(freq_range * fft_power) / total_power
                features.loc[i, 'spectral_rolloff'] = np.percentile(fft_values, Config.FFT_PERCENTILE)
                features.loc[i, 'spectral_energy'] = total_power

                # High frequency energy ratio
                mid_point = len(fft_values) // 2
                high_freq_energy = np.sum(fft_power[mid_point:])
                features.loc[i, 'high_freq_ratio'] = high_freq_energy / total_power
            else:
                features.loc[i, 'spectral_centroid'] = 0
                features.loc[i, 'spectral_rolloff'] = 0
                features.loc[i, 'spectral_energy'] = 0
                features.loc[i, 'high_freq_ratio'] = 0

            # Peak detection
            peaks, _ = find_peaks(fft_values, height=np.mean(fft_values))
            features.loc[i, 'num_spectral_peaks'] = len(peaks)

        return features

    def create_astronomical_features(self, X: pd.DataFrame) -> pd.DataFrame:
        """Create domain-specific features for exoplanet transit detection."""
        print("Creating astronomical features...")

        features = pd.DataFrame(index=X.index)

        for i, row in X.iterrows():
            values = row.values

            # Detrend the signal
            x_vals = np.arange(len(values))
            try:
                slope, intercept, r_value, _, _ = stats.linregress(x_vals, values)
                detrended = values - (slope * x_vals + intercept)
                features.loc[i, 'trend_slope'] = slope
                features.loc[i, 'trend_r_squared'] = r_value ** 2
            except:
                detrended = values - np.mean(values)
                features.loc[i, 'trend_slope'] = 0
                features.loc[i, 'trend_r_squared'] = 0

            # Transit detection features
            std_thresh = np.std(detrended)
            features.loc[i, 'max_dip'] = np.min(detrended)
            features.loc[i, 'dip_duration'] = np.sum(detrended < -std_thresh)
            features.loc[i, 'num_significant_dips'] = len(find_peaks(-detrended, height=std_thresh)[0])

            # Variability measures
            diff_values = np.diff(values)
            features.loc[i, 'total_variation'] = np.sum(np.abs(diff_values))
            features.loc[i, 'max_change'] = np.max(np.abs(diff_values))

            # Autocorrelation
            if len(values) > 1:
                autocorr_1 = np.corrcoef(values[:-1], values[1:])[0, 1]
                features.loc[i, 'autocorr_1'] = autocorr_1 if not np.isnan(autocorr_1) else 0
            else:
                features.loc[i, 'autocorr_1'] = 0

        return features

    def create_all_features(self, X: pd.DataFrame) -> pd.DataFrame:
        """Combine all feature engineering methods."""
        print("Starting comprehensive feature engineering...")

        # Create all feature types
        stat_features = self.create_statistical_features(X)
        rolling_features = self.create_rolling_features_fixed(X)  # Fixed version
        freq_features = self.create_frequency_features(X)
        astro_features = self.create_astronomical_features(X)

        # Combine all features
        all_features = pd.concat([
            X,  # Original features
            stat_features,
            rolling_features,
            freq_features,
            astro_features
        ], axis=1)

        print(f"Feature engineering completed. Total features: {all_features.shape[1]}")
        return all_features


class FeatureSelector:
    """Feature selection optimized for minority class detection."""

    def __init__(self):
        self.selected_features: Optional[list] = None
        self.feature_scores: Optional[pd.DataFrame] = None

    def combined_selection(self, X: pd.DataFrame, y: pd.Series, final_k: int) -> Tuple[pd.DataFrame, list, pd.DataFrame]:
        """Combined feature selection with emphasis on minority class detection."""
        print("Applying combined feature selection...")

        # Univariate selection with F-score
        print("- Univariate selection...")
        uni_selector = SelectKBest(score_func=f_classif, k=Config.UNIVARIATE_K)
        uni_selector.fit(X, y)
        uni_scores = pd.DataFrame({
            'feature': X.columns,
            'f_score': uni_selector.scores_
        })

        # Mutual information selection
        print("- Mutual information selection...")
        mi_scores = mutual_info_classif(X, y, random_state=RANDOM_STATE)
        mi_df = pd.DataFrame({
            'feature': X.columns,
            'mi_score': mi_scores
        })

        # Random Forest importance with balanced class weights
        print("- Importance-based selection...")
        rf = RandomForestClassifier(
            n_estimators=200,
            random_state=RANDOM_STATE,
            n_jobs=-1,
            class_weight='balanced',
            max_depth=15,
            min_samples_split=2,
            min_samples_leaf=1
        )
        rf.fit(X, y)

        importance_df = pd.DataFrame({
            'feature': X.columns,
            'importance': rf.feature_importances_
        })

        # Combine scores
        combined = pd.merge(uni_scores, mi_df, on='feature')
        combined = pd.merge(combined, importance_df, on='feature')

        # Normalize scores
        for score_col in ['f_score', 'mi_score', 'importance']:
            col_min, col_max = combined[score_col].min(), combined[score_col].max()
            if col_max > col_min:
                combined[f'{score_col}_norm'] = (combined[score_col] - col_min) / (col_max - col_min)
            else:
                combined[f'{score_col}_norm'] = 0

        # Weighted combination (higher weight on mutual information for imbalanced data)
        combined['combined_score'] = (
            combined['f_score_norm'] * 0.25 +
            combined['mi_score_norm'] * 0.5 +  # Higher weight for MI
            combined['importance_norm'] * 0.25
        )

        # Select top features
        combined = combined.sort_values('combined_score', ascending=False)
        top_features = combined.head(final_k)['feature'].tolist()

        self.selected_features = top_features
        self.feature_scores = combined

        print(f"Feature selection completed. Selected: {len(top_features)} features")
        return X[top_features], top_features, combined


class ModelTrainer:
    """Model trainer optimized for minority class detection without SMOTE."""

    def __init__(self):
        self.model: Optional[lgb.Booster] = None
        self.cv_results: Dict[str, list] = {}

    def train_with_cv(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, Any]:
        """Train model with CV focusing on minority class detection."""
        print("Starting model training optimized for minority class...")

        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=Config.TEST_SIZE, random_state=RANDOM_STATE, stratify=y
        )

        print(f"Train distribution: {Counter(y_train)}")
        print(f"Test distribution: {Counter(y_test)}")

        # Cross-validation
        cv_results = self._cross_validate(X_train, y_train)

        # Final model training
        final_model = self._train_final_model(X_train, y_train, X_test, y_test)

        # Evaluation
        test_results = self._evaluate_model(final_model, X_test, y_test)

        return {
            'model': final_model,
            'cv_results': cv_results,
            'test_results': test_results,
            'X_test': X_test,
            'y_test': y_test
        }

    def _cross_validate(self, X_train: pd.DataFrame, y_train: pd.Series) -> Dict[str, list]:
        """Perform stratified cross-validation."""
        skf = StratifiedKFold(n_splits=Config.CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)

        cv_results = {
            'accuracy': [], 'precision': [], 'recall': [], 'f1': [],
            'auc': [], 'avg_precision': []
        }

        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):
            print(f"\nTraining fold {fold}/{Config.CV_FOLDS}")

            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]
            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]

            # Train model
            model = self._train_lgb_model(X_tr, y_tr, X_val, y_val)

            # Predictions
            y_prob = model.predict(X_val, num_iteration=model.best_iteration)
            y_pred = (y_prob >= Config.CLASSIFICATION_THRESHOLD).astype(int)

            # Calculate metrics
            cv_results['accuracy'].append(accuracy_score(y_val, y_pred))
            cv_results['precision'].append(precision_score(y_val, y_pred, zero_division=0))
            cv_results['recall'].append(recall_score(y_val, y_pred, zero_division=0))
            cv_results['f1'].append(f1_score(y_val, y_pred, zero_division=0))
            cv_results['auc'].append(roc_auc_score(y_val, y_prob))
            cv_results['avg_precision'].append(average_precision_score(y_val, y_prob))

            print(f"Fold {fold} - Precision: {cv_results['precision'][-1]:.3f}, "
                  f"Recall: {cv_results['recall'][-1]:.3f}, F1: {cv_results['f1'][-1]:.3f}, "
                  f"AUC: {cv_results['auc'][-1]:.3f}")

        # Print CV summary
        self._print_cv_results(cv_results)
        return cv_results

    def _train_lgb_model(self, X_train: pd.DataFrame, y_train: pd.Series,
                        X_val: pd.DataFrame, y_val: pd.Series) -> lgb.Booster:
        """Train LightGBM model optimized for minority class detection."""
        lgb_train = lgb.Dataset(X_train, label=y_train)
        lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train)

        model = lgb.train(
            Config.LGBM_PARAMS,
            lgb_train,
            num_boost_round=Config.NUM_BOOST_ROUNDS,
            valid_sets=[lgb_train, lgb_val],
            valid_names=['train', 'eval'],
            callbacks=[
                lgb.early_stopping(stopping_rounds=Config.EARLY_STOPPING_ROUNDS),
                lgb.log_evaluation(0)
            ]
        )

        return model

    def _train_final_model(self, X_train: pd.DataFrame, y_train: pd.Series,
                          X_test: pd.DataFrame, y_test: pd.Series) -> lgb.Booster:
        """Train final model on full training set."""
        print("\nTraining final model...")
        self.model = self._train_lgb_model(X_train, y_train, X_test, y_test)
        return self.model

    def _evaluate_model(self, model: lgb.Booster, X_test: pd.DataFrame,
                       y_test: pd.Series) -> Dict[str, Any]:
        """Evaluate model with comprehensive metrics."""
        y_prob = model.predict(X_test, num_iteration=model.best_iteration)
        y_pred = (y_prob >= Config.CLASSIFICATION_THRESHOLD).astype(int)

        return {
            'probabilities': y_prob,
            'predictions': y_pred,
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1': f1_score(y_test, y_pred, zero_division=0),
            'auc': roc_auc_score(y_test, y_prob),
            'avg_precision': average_precision_score(y_test, y_prob),
            'confusion_matrix': confusion_matrix(y_test, y_pred)
        }

    def _print_cv_results(self, cv_results: Dict[str, list]):
        """Print cross-validation results."""
        print("\n=== CROSS-VALIDATION RESULTS ===")
        for metric in ['accuracy', 'precision', 'recall', 'f1', 'auc', 'avg_precision']:
            scores = cv_results[metric]
            print(f"{metric.replace('_', ' ').title()}: {np.mean(scores):.4f} ¬± {np.std(scores):.4f}")


class ExoplanetClassifierPipeline:
    """Main pipeline class for exoplanet classification."""

    def __init__(self):
        self.preprocessor = DataPreprocessor()
        self.feature_engineer = FeatureEngineer()
        self.feature_selector = FeatureSelector()
        self.model_trainer = ModelTrainer()
        self.results: Optional[Dict[str, Any]] = None

    def run_full_pipeline(self, df: pd.DataFrame, target_features: int = None) -> Dict[str, Any]:
        """Execute the complete ML pipeline."""
        if target_features is None:
            target_features = Config.TARGET_FEATURES

        print("=== EXOPLANET CLASSIFICATION PIPELINE ===")
        print(f"Starting pipeline with dataset shape: {df.shape}")

        # Phase 1: Data Preprocessing
        print("\n=== PHASE 1: DATA PREPROCESSING ===")
        X_clean, y_clean = self.preprocessor.clean_data(df)

        # Phase 2: Feature Engineering
        print("\n=== PHASE 2: FEATURE ENGINEERING ===")
        X_with_features = self.feature_engineer.create_all_features(X_clean)

        # Phase 3: Feature Selection
        print("\n=== PHASE 3: FEATURE SELECTION ===")
        X_selected, selected_features, feature_scores = self.feature_selector.combined_selection(
            X_with_features, y_clean, final_k=target_features
        )

        # Phase 4: Feature Scaling
        print("\n=== PHASE 4: FEATURE SCALING ===")
        X_final, _ = self.preprocessor.scale_features(X_selected)

        # Phase 5: Model Training
        print("\n=== PHASE 5: MODEL TRAINING ===")
        # Convert labels (2 -> 1, 1 -> 0)
        y_binary = y_clean.replace({2: 1, 1: 0})

        training_results = self.model_trainer.train_with_cv(X_final, y_binary)

        # Store results
        self.results = {
            'X_final': X_final,
            'y_final': y_binary,
            'selected_features': selected_features,
            'feature_scores': feature_scores,
            'model_results': training_results,
            'preprocessor': self.preprocessor,
            'feature_engineer': self.feature_engineer,
            'feature_selector': self.feature_selector,
            'model_trainer': self.model_trainer,
            'original_shape': df.shape,
            'final_shape': X_final.shape
        }

        # Print summary
        self._print_pipeline_summary()

        return self.results

    def _print_pipeline_summary(self):
        """Print comprehensive pipeline summary."""
        if self.results is None:
            return

        print(f"\n=== PIPELINE SUMMARY ===")
        print(f"Original dataset shape: {self.results['original_shape']}")
        print(f"Final dataset shape: {self.results['final_shape']}")
        print(f"Feature reduction: {self.results['original_shape'][1]-1} ‚Üí {self.results['final_shape'][1]}")
        print(f"Label distribution:\n{self.results['y_final'].value_counts().sort_index()}")

        # Test results
        test_results = self.results['model_results']['test_results']

        print(f"\n=== FINAL TEST RESULTS ===")
        print(f"Accuracy: {test_results['accuracy']:.4f}")
        print(f"Precision: {test_results['precision']:.4f}")
        print(f"Recall: {test_results['recall']:.4f}")
        print(f"F1-Score: {test_results['f1']:.4f}")
        print(f"AUC-ROC: {test_results['auc']:.4f}")
        print(f"Average Precision: {test_results['avg_precision']:.4f}")
        print(f"Confusion Matrix:\n{test_results['confusion_matrix']}")

    def predict_on_new_data(self, new_df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """Make predictions on new dataset."""
        if self.results is None:
            raise ValueError("Pipeline must be trained first")

        print("Processing new data through pipeline...")

        # Process through same pipeline
        X_clean, _ = self.preprocessor.clean_data(new_df)
        X_with_features = self.feature_engineer.create_all_features(X_clean)
        X_selected = X_with_features[self.results['selected_features']]
        X_final, _ = self.preprocessor.scale_features(X_selected)

        # Make predictions
        model = self.results['model_results']['model']
        y_prob = model.predict(X_final, num_iteration=model.best_iteration)
        y_pred = (y_prob >= Config.CLASSIFICATION_THRESHOLD).astype(int)

        return y_pred, y_prob

    def save_results(self, filepath: str):
        """Save pipeline results."""
        if self.results is not None:
            with open(filepath, 'wb') as f:
                pickle.dump(self.results, f)
            print(f"‚úÖ Results saved to {filepath}")
        else:
            print("‚ùå No results to save")



def save_for_api(results: Dict[str, Any]):
    """Guardar todos los componentes para la API."""
    print("\nüíæ GUARDANDO COMPONENTES PARA LA API...")
    
    try:
        # Crear directorio
        api_dir = "../backend/model"
        os.makedirs(api_dir, exist_ok=True)
        
        # Guardar modelo LightGBM
        model = results['model_results']['model']
        joblib.dump(model, f"{api_dir}/lightgbm_model.pkl")
        print("‚úÖ Modelo LightGBM guardado")
        
        # Guardar componentes de preprocesamiento
        joblib.dump(results['preprocessor'], f"{api_dir}/preprocessor.pkl")
        joblib.dump(results['feature_engineer'], f"{api_dir}/feature_engineer.pkl")
        joblib.dump(results['feature_selector'], f"{api_dir}/feature_selector.pkl")
        print("‚úÖ Componentes de preprocesamiento guardados")
        
        # Guardar caracter√≠sticas seleccionadas
        pd.DataFrame({'feature': results['selected_features']}).to_csv(
            f"{api_dir}/selected_features.csv", index=False
        )
        print("‚úÖ Caracter√≠sticas seleccionadas guardadas")
        
        # Guardar informaci√≥n del modelo
        test_results = results['model_results']['test_results']
        model_info = {
            "model_type": "LightGBM",
            "accuracy": float(test_results['accuracy']),
            "precision": float(test_results['precision']),
            "recall": float(test_results['recall']),
            "f1": float(test_results['f1']),
            "auc": float(test_results['auc']),
            "avg_precision": float(test_results['avg_precision']),
            "features_count": len(results['selected_features']),
            "original_features": results['original_shape'][1] - 1,
            "final_features": results['final_shape'][1],
            "training_samples": len(results['y_final']),
            "test_samples": len(results['model_results']['y_test']),
            "class_distribution": {
                "no_exoplanet": int(np.sum(results['y_final'] == 0)),
                "exoplanet": int(np.sum(results['y_final'] == 1))
            }
        }
        
        with open(f"{api_dir}/model_info.json", "w") as f:
            json.dump(model_info, f, indent=2, default=str)
        
        print("‚úÖ Informaci√≥n del modelo guardada")
        print(f"üìÅ Archivos guardados en: {api_dir}")
        
        # Verificar archivos guardados
        saved_files = [
            "lightgbm_model.pkl",
            "preprocessor.pkl", 
            "feature_engineer.pkl",
            "feature_selector.pkl",
            "selected_features.csv",
            "model_info.json"
        ]
        
        print("üìã Archivos para la API:")
        for file in saved_files:
            filepath = f"{api_dir}/{file}"
            if os.path.exists(filepath):
                size_mb = os.path.getsize(filepath) / (1024 * 1024)
                print(f"   ‚úÖ {file} ({size_mb:.2f} MB)")
            else:
                print(f"   ‚ùå {file} (FALTANTE)")
                
    except Exception as e:
        print(f"‚ùå Error guardando componentes para API: {e}")
        import traceback
        traceback.print_exc()



def main():
    """Main execution function."""
    try:
        # Initialize pipeline
        pipeline = ExoplanetClassifierPipeline()

        # Load data
        train_df, test_df = DataLoader.load_train_test_datasets()

        # Run pipeline
        results = pipeline.run_full_pipeline(train_df, target_features=Config.TARGET_FEATURES)

        # Save results
        pipeline.save_results("improved_exoplanet_results.pkl")

        save_for_api(results)

        # Test on external data if available
        if test_df is not None:
            print("\n=== EXTERNAL TEST EVALUATION ===")

            y_pred_external, y_prob_external = pipeline.predict_on_new_data(test_df)

            if 'LABEL' in test_df.columns:
                y_test_true = test_df['LABEL'].replace({2: 1, 1: 0})

                print(f"External Test Results:")
                print(f"Accuracy: {accuracy_score(y_test_true, y_pred_external):.4f}")
                print(f"Precision: {precision_score(y_test_true, y_pred_external, zero_division=0):.4f}")
                print(f"Recall: {recall_score(y_test_true, y_pred_external, zero_division=0):.4f}")
                print(f"F1-Score: {f1_score(y_test_true, y_pred_external, zero_division=0):.4f}")
                print(f"AUC-ROC: {roc_auc_score(y_test_true, y_prob_external):.4f}")
                print(f"Average Precision: {average_precision_score(y_test_true, y_prob_external):.4f}")
                print(f"Confusion Matrix:\n{confusion_matrix(y_test_true, y_pred_external)}")
            else:
                print(f"Predictions distribution: {Counter(y_pred_external)}")

        print("\nüéâ Pipeline completed successfully!")
        print("\nüìä Key Improvements:")
        print("- Removed SMOTE completely")
        print("- Fixed rolling window features (no axis parameter)")
        print("- Optimized LightGBM for minority class detection")
        print("- Conservative preprocessing to preserve patterns")
        print("- Enhanced feature engineering for transit detection")
        print("- Added AUC and Average Precision metrics")

    except Exception as e:
        print(f"‚ùå Pipeline failed with error: {str(e)}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()